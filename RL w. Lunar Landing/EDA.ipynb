{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TYH71/DELE_CA2_RL/blob/main/Untitled32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHNUelOunMhW"
      },
      "source": [
        "# LunarLanderV2 Attempted using DQN (Keras)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MbG4isytAtAT"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AquMVsLdB2up"
      },
      "source": [
        "## Description\n",
        "\n",
        "This environment is a classic rocket trajectory optimization problem.\n",
        "\n",
        "According to Pontryagin's maximum principle, it is optimal to fire the engine at full throttle or turn it off. This is the reason why this environment has discreet actions: engine on or off.\n",
        "\n",
        "There are two environment versions: discrete or continuous.\n",
        "\n",
        "The landing pad is always at coordinates (0,0). The coordinates are the first two numbers in the state vector.\n",
        "\n",
        "Landing outside the landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt.\n",
        "\n",
        "## Action Space\n",
        "\n",
        "There are four discrete actions available: `do nothing`, `fire left\n",
        "orientation engine`, `fire main engine`, `fire right orientation engine`.\n",
        "\n",
        "| Action | Description |\n",
        "| :--: | :--: |\n",
        "| 0 | Do Nothing |\n",
        "| 1 | Fire Left Orientation Engine |\n",
        "| 2 | Fire Main Engine |\n",
        "| 3 | Fire Right Orientation Engine |\n",
        "\n",
        "## Observation Space\n",
        "\n",
        "There are 8 states: the coordinates of the lander in `x` & `y`, its linear velocities in `x` & `y`, its angle, its angular velocity, and two booleans showing if each leg is in contact with the ground or not.\n",
        "\n",
        "## Reward \n",
        "\n",
        "> Solving the scenario is capped at 200 points.\n",
        "\n",
        "| Reward Scenario | Points |\n",
        "| :--: | :--: |\n",
        "| Moving from top of the screen to the landing pad and zero speed | 100-140 |\n",
        "| Moves away from the landing pad | Lose Reward |\n",
        "| Lander Crashes | -100 |\n",
        "| Lander comes to rest | +100 |\n",
        "| Each leg with ground contact | +10 |\n",
        "| Firing Main Engine | -0.3 per frame |\n",
        "| Firing Side Engine | -0.03 per frame |\n",
        "\n",
        "## Episode Termination\n",
        "\n",
        "The episode finishes if:\n",
        "\n",
        "1. lander crashes (in contact with the moon)\n",
        "2. lander gets outside of the viewport (`x` coordinate is greater than 1)\n",
        "3. lander is not awake (body doesn't move and doesn't collide with any other body)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ll2Kl_OSBO2Y"
      },
      "outputs": [],
      "source": [
        "env = gym.make('LunarLander-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7iL3BsGA4xt",
        "outputId": "f427a256-d0b3-42b3-de10-03613903a851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Activation Space: Discrete(4)\n",
            "Number of Observation Space: (8,)\n"
          ]
        }
      ],
      "source": [
        "# Number of Action Space\n",
        "print(\"Number of Activation Space: {}\".format(env.action_space))\n",
        "\n",
        "# Number of Observation Space\n",
        "# Reference: https://github.com/openai/gym/blob/58aeddb62fb9d46d2d2481d1f7b0a380d8c454b1/gym/spaces/box.py#L44\n",
        "obs_space = env.observation_space.shape\n",
        "print(\"Number of Observation Space: {}\".format(obs_space))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr89NiSyJFMw",
        "outputId": "acb12bea-c420-4ddf-dd07-c83cad19b0e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8,)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_space.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CJx6SQxbSpYO"
      },
      "outputs": [],
      "source": [
        "done = False\n",
        "env = gym.make('LunarLander-v2')\n",
        "env.reset()\n",
        "monitor = gym.wrappers.Monitor(env, './EDA Video/Random', force=True)\n",
        "monitor.reset()\n",
        "while done == False:\n",
        "    random_action = env.action_space.sample()\n",
        "    state, reward, done, info = monitor.step(random_action)\n",
        "\n",
        "env.close()\n",
        "monitor.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Action 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "done = False\n",
        "env = gym.make('LunarLander-v2')\n",
        "env.reset()\n",
        "monitor = gym.wrappers.Monitor(env, './EDA Video/Action 0', force=True)\n",
        "monitor.reset()\n",
        "while done == False:\n",
        "    random_action = env.action_space.sample()\n",
        "    state, reward, done, info = monitor.step(0)\n",
        "\n",
        "env.close()\n",
        "monitor.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Action 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "done = False\n",
        "env = gym.make('LunarLander-v2')\n",
        "env.reset()\n",
        "monitor = gym.wrappers.Monitor(env, './EDA Video/Action 1', force=True)\n",
        "monitor.reset()\n",
        "while done == False:\n",
        "    random_action = env.action_space.sample()\n",
        "    state, reward, done, info = monitor.step(1)\n",
        "\n",
        "env.close()\n",
        "monitor.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Action 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "done = False\n",
        "env = gym.make('LunarLander-v2')\n",
        "env.reset()\n",
        "monitor = gym.wrappers.Monitor(env, './EDA Video/Action 2', force=True)\n",
        "monitor.reset()\n",
        "while done == False:\n",
        "    random_action = env.action_space.sample()\n",
        "    state, reward, done, info = monitor.step(2)\n",
        "\n",
        "env.close()\n",
        "monitor.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Action 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "done = False\n",
        "env = gym.make('LunarLander-v2')\n",
        "env.reset()\n",
        "monitor = gym.wrappers.Monitor(env, './EDA Video/Action 3', force=True)\n",
        "monitor.reset()\n",
        "while done == False:\n",
        "    state, reward, done, info = monitor.step(3)\n",
        "\n",
        "env.close()\n",
        "monitor.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMK5exZTE+cWnOL2iSjLFOe",
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "Untitled32.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
