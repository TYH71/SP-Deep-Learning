{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import uuid\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Box([-inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf], (8,), float32)\n",
      "Output: Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "print(f\"Input: {env.observation_space}\")\n",
    "print(f\"Output: {env.action_space}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def masked_huber_loss(mask_value, clip_delta):\n",
    "  def f(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    cond  = K.abs(error) < clip_delta\n",
    "    mask_true = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "    masked_squared_error = 0.5 * K.square(mask_true * (y_true - y_pred))\n",
    "    linear_loss  = mask_true * (clip_delta * K.abs(error) - 0.5 * (clip_delta ** 2))\n",
    "    huber_loss = tf.where(cond, masked_squared_error, linear_loss)\n",
    "    return K.sum(huber_loss) / K.sum(mask_true)\n",
    "  f.__name__ = 'masked_huber_loss'\n",
    "  return f"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "input_shape = (9,) # 8 variables in the environment + the fraction finished we add ourselves\n",
    "outputs = 4\n",
    "\n",
    "def create_model(learning_rate, regularization_factor):\n",
    "  model = Sequential([\n",
    "    Dense(64, input_shape=input_shape, activation=\"relu\", kernel_regularizer=l2(regularization_factor)),\n",
    "    Dense(64, activation=\"relu\", kernel_regularizer=l2(regularization_factor)),\n",
    "    Dense(64, activation=\"relu\", kernel_regularizer=l2(regularization_factor)),\n",
    "    Dense(outputs, activation='linear', kernel_regularizer=l2(regularization_factor))\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "  model.compile(optimizer=optimizer, loss=masked_huber_loss(0.0, 1.0))\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_q_values(model, state):\n",
    "  input = state[np.newaxis, ...]\n",
    "  return model.predict(input)[0]\n",
    "\n",
    "def get_multiple_q_values(model, states):\n",
    "  return model.predict(states)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def select_action_epsilon_greedy(q_values, epsilon):\n",
    "  random_value = random.uniform(0, 1)\n",
    "  if random_value < epsilon:\n",
    "    return random.randint(0, len(q_values) - 1)\n",
    "  else:\n",
    "    return np.argmax(q_values)\n",
    "\n",
    "def select_best_action(q_values):\n",
    "  return np.argmax(q_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class StateTransition():\n",
    "\n",
    "  def __init__(self, old_state, action, reward, new_state, done):\n",
    "    self.old_state = old_state\n",
    "    self.action = action\n",
    "    self.reward = reward\n",
    "    self.new_state = new_state\n",
    "    self.done = done\n",
    "\n",
    "class ReplayBuffer():\n",
    "  current_index = 0\n",
    "\n",
    "  def __init__(self, size = 10000):\n",
    "    self.size = size\n",
    "    self.transitions = []\n",
    "\n",
    "  def add(self, transition):\n",
    "    if len(self.transitions) < self.size:\n",
    "      self.transitions.append(transition)\n",
    "    else:\n",
    "      self.transitions[self.current_index] = transition\n",
    "      self.__increment_current_index()\n",
    "\n",
    "  def length(self):\n",
    "    return len(self.transitions)\n",
    "\n",
    "  def get_batch(self, batch_size):\n",
    "    return random.sample(self.transitions, batch_size)\n",
    "\n",
    "  def __increment_current_index(self):\n",
    "    self.current_index += 1\n",
    "    if self.current_index >= self.size - 1:\n",
    "      self.current_index = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def calculate_target_values(model, target_model, state_transitions, discount_factor):\n",
    "  states = []\n",
    "  new_states = []\n",
    "  for transition in state_transitions:\n",
    "    states.append(transition.old_state)\n",
    "    new_states.append(transition.new_state)\n",
    "\n",
    "  new_states = np.array(new_states)\n",
    "\n",
    "  q_values_new_state = get_multiple_q_values(model, new_states)\n",
    "  q_values_new_state_target_model = get_multiple_q_values(target_model, new_states)\n",
    "\n",
    "  targets = []\n",
    "  for index, state_transition in enumerate(state_transitions):\n",
    "    best_action = select_best_action(q_values_new_state[index])\n",
    "    best_action_next_state_q_value = q_values_new_state_target_model[index][best_action]\n",
    "\n",
    "    if state_transition.done:\n",
    "      target_value = state_transition.reward\n",
    "    else:\n",
    "      target_value = state_transition.reward + discount_factor * best_action_next_state_q_value\n",
    "\n",
    "    target_vector = [0] * outputs\n",
    "    target_vector[state_transition.action] = target_value\n",
    "    targets.append(target_vector)\n",
    "\n",
    "  return np.array(targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_model(model, states, targets):\n",
    "  model.fit(states, targets, epochs=1, batch_size=len(targets), verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def copy_model(model):\n",
    "  backup_file = 'backup_'+str(uuid.uuid4())\n",
    "  model.save(backup_file)\n",
    "  new_model = load_model(backup_file, custom_objects={ 'masked_huber_loss': masked_huber_loss(0.0, 1.0) })\n",
    "  shutil.rmtree(backup_file)\n",
    "  return new_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class AverageRewardTracker():\n",
    "  current_index = 0\n",
    "\n",
    "  def __init__(self, num_rewards_for_average=100):\n",
    "    self.num_rewards_for_average = num_rewards_for_average\n",
    "    self.last_x_rewards = []\n",
    "\n",
    "  def add(self, reward):\n",
    "    if len(self.last_x_rewards) < self.num_rewards_for_average:\n",
    "      self.last_x_rewards.append(reward)\n",
    "    else:\n",
    "      self.last_x_rewards[self.current_index] = reward\n",
    "      self.__increment_current_index()\n",
    "\n",
    "  def __increment_current_index(self):\n",
    "    self.current_index += 1\n",
    "    if self.current_index >= self.num_rewards_for_average:\n",
    "      self.current_index = 0\n",
    "\n",
    "  def get_average(self):\n",
    "    return np.average(self.last_x_rewards)\n",
    "\n",
    "\n",
    "class FileLogger():\n",
    "\n",
    "  def __init__(self, file_name='progress.log'):\n",
    "    self.file_name = file_name\n",
    "    self.clean_progress_file()\n",
    "\n",
    "  def log(self, episode, steps, reward, average_reward):\n",
    "    f = open(self.file_name, 'a+')\n",
    "    f.write(f\"{episode};{steps};{reward};{average_reward}\\n\")\n",
    "    f.close()\n",
    "\n",
    "  def clean_progress_file(self):\n",
    "    if os.path.exists(self.file_name):\n",
    "      os.remove(self.file_name)\n",
    "    f = open(self.file_name, 'a+')\n",
    "    f.write(\"episode;steps;reward;average\\n\")\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "replay_buffer_size = 200000\n",
    "learning_rate = 0.001\n",
    "regularization_factor = 0.001\n",
    "training_batch_size = 128\n",
    "training_start = 256\n",
    "max_episodes = 10000\n",
    "max_steps = 1000\n",
    "target_network_replace_frequency_steps = 1000\n",
    "model_backup_frequency_episodes = 100\n",
    "starting_epsilon = 1.0\n",
    "minimum_epsilon = 0.01\n",
    "epsilon_decay_factor_per_episode = 0.995\n",
    "discount_factor = 0.99\n",
    "train_every_x_steps = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: backup_3b0c2315-52c4-4424-9fdc-9c377e6d95d9\\assets\n",
      "Starting episode 0 with epsilon 1.0\n",
      "Q values: [-0.07638863  0.04713185 -0.05401849 -0.08274545]\n",
      "Max Q: 0.047131847590208054\n",
      "episode 0 finished in 94 steps with reward -220.8548845647292. Average reward over last 100: -220.8548845647292\n",
      "Starting episode 1 with epsilon 0.995\n",
      "Q values: [-0.04214855  0.06018496 -0.08832683 -0.07152963]\n",
      "Max Q: 0.060184963047504425\n",
      "episode 1 finished in 79 steps with reward -208.7637684117051. Average reward over last 100: -214.80932648821715\n",
      "Starting episode 2 with epsilon 0.990025\n",
      "Q values: [-0.02013846  0.11983025 -0.10184277 -0.04828166]\n",
      "Max Q: 0.11983025074005127\n",
      "episode 2 finished in 114 steps with reward -450.96800994628563. Average reward over last 100: -293.52888764090665\n",
      "Starting episode 3 with epsilon 0.985074875\n",
      "Q values: [-0.3467437  -0.19181173 -0.13803567 -0.30827042]\n",
      "Max Q: -0.13803566992282867\n",
      "episode 3 finished in 79 steps with reward -160.49442147607948. Average reward over last 100: -260.27027109969987\n",
      "Starting episode 4 with epsilon 0.9801495006250001\n",
      "Q values: [-1.6568625 -1.225592  -0.5617645 -1.2678064]\n",
      "Max Q: -0.5617644786834717\n",
      "episode 4 finished in 86 steps with reward -88.65204989417916. Average reward over last 100: -225.94662685859572\n",
      "Starting episode 5 with epsilon 0.9752487531218751\n",
      "Q values: [-0.88141805 -0.9573964  -0.5597287  -1.1141695 ]\n",
      "Max Q: -0.5597286820411682\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m replay_buffer\u001B[38;5;241m.\u001B[39mlength() \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m training_start \u001B[38;5;129;01mand\u001B[39;00m step_count \u001B[38;5;241m%\u001B[39m train_every_x_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     46\u001B[0m   batch \u001B[38;5;241m=\u001B[39m replay_buffer\u001B[38;5;241m.\u001B[39mget_batch(batch_size\u001B[38;5;241m=\u001B[39mtraining_batch_size)\n\u001B[1;32m---> 47\u001B[0m   targets \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_target_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdiscount_factor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m   states \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([state_transition\u001B[38;5;241m.\u001B[39mold_state \u001B[38;5;28;01mfor\u001B[39;00m state_transition \u001B[38;5;129;01min\u001B[39;00m batch])\n\u001B[0;32m     49\u001B[0m   train_model(model, states, targets)\n",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36mcalculate_target_values\u001B[1;34m(model, target_model, state_transitions, discount_factor)\u001B[0m\n\u001B[0;32m      6\u001B[0m   new_states\u001B[38;5;241m.\u001B[39mappend(transition\u001B[38;5;241m.\u001B[39mnew_state)\n\u001B[0;32m      8\u001B[0m new_states \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(new_states)\n\u001B[1;32m---> 10\u001B[0m q_values_new_state \u001B[38;5;241m=\u001B[39m \u001B[43mget_multiple_q_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m q_values_new_state_target_model \u001B[38;5;241m=\u001B[39m get_multiple_q_values(target_model, new_states)\n\u001B[0;32m     13\u001B[0m targets \u001B[38;5;241m=\u001B[39m []\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36mget_multiple_q_values\u001B[1;34m(model, states)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_multiple_q_values\u001B[39m(model, states):\n\u001B[1;32m----> 6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstates\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\keras\\engine\\training.py:1758\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1750\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m   1751\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1752\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUsing Model.predict with \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1753\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMultiWorkerDistributionStrategy or TPUStrategy and \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1754\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAutoShardPolicy.FILE might lead to out-of-order result\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1755\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Consider setting it to AutoShardPolicy.DATA.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1756\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m-> 1758\u001B[0m data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1759\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1761\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1762\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1763\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1764\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1765\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1766\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1767\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1768\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1770\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[0;32m   1771\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\keras\\engine\\data_adapter.py:1403\u001B[0m, in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1402\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1403\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataHandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\keras\\engine\\data_adapter.py:1153\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1150\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[0;32m   1152\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[1;32m-> 1153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1162\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1163\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1165\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1167\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[0;32m   1169\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\keras\\engine\\data_adapter.py:325\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    322\u001B[0m     flat_dataset \u001B[38;5;241m=\u001B[39m flat_dataset\u001B[38;5;241m.\u001B[39mshuffle(\u001B[38;5;241m1024\u001B[39m)\u001B[38;5;241m.\u001B[39mrepeat(epochs)\n\u001B[0;32m    323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m flat_dataset\n\u001B[1;32m--> 325\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mindices_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43mslice_batch_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    327\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mslice_inputs(indices_dataset, inputs)\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2048\u001B[0m, in \u001B[0;36mDatasetV2.flat_map\u001B[1;34m(self, map_func, name)\u001B[0m\n\u001B[0;32m   2014\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_map\u001B[39m(\u001B[38;5;28mself\u001B[39m, map_func, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   2015\u001B[0m   \u001B[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001B[39;00m\n\u001B[0;32m   2016\u001B[0m \n\u001B[0;32m   2017\u001B[0m \u001B[38;5;124;03m  The type signature is:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2046\u001B[0m \u001B[38;5;124;03m    Dataset: A `Dataset`.\u001B[39;00m\n\u001B[0;32m   2047\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2048\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFlatMapDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5549\u001B[0m, in \u001B[0;36mFlatMapDataset.__init__\u001B[1;34m(self, input_dataset, map_func, name)\u001B[0m\n\u001B[0;32m   5547\u001B[0m \u001B[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001B[39;00m\n\u001B[0;32m   5548\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[1;32m-> 5549\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5550\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure, DatasetSpec):\n\u001B[0;32m   5552\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   5553\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   5554\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_get_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure)\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4533\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[0;32m   4526\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   4527\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4528\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4529\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4530\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   4531\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[1;32m-> 4533\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4534\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[0;32m   4535\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3244\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3235\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   3236\u001B[0m   \u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[0;32m   3237\u001B[0m \n\u001B[0;32m   3238\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3242\u001B[0m \u001B[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[0;32m   3243\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 3244\u001B[0m   graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_concrete_function_garbage_collected\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3245\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3246\u001B[0m   graph_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   3247\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3210\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3208\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   3209\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m-> 3210\u001B[0m   graph_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3211\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[0;32m   3212\u001B[0m   captured \u001B[38;5;241m=\u001B[39m object_identity\u001B[38;5;241m.\u001B[39mObjectIdentitySet(\n\u001B[0;32m   3213\u001B[0m       graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minternal_captures)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3557\u001B[0m, in \u001B[0;36mFunction._maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3553\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_define_function_with_shape_relaxation(\n\u001B[0;32m   3554\u001B[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[0;32m   3556\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mmissed\u001B[38;5;241m.\u001B[39madd(call_context_key)\n\u001B[1;32m-> 3557\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mprimary[cache_key] \u001B[38;5;241m=\u001B[39m graph_function\n\u001B[0;32m   3560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function, filtered_flat_args\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3392\u001B[0m, in \u001B[0;36mFunction._create_graph_function\u001B[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m   3387\u001B[0m missing_arg_names \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   3388\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (arg, i) \u001B[38;5;28;01mfor\u001B[39;00m i, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(missing_arg_names)\n\u001B[0;32m   3389\u001B[0m ]\n\u001B[0;32m   3390\u001B[0m arg_names \u001B[38;5;241m=\u001B[39m base_arg_names \u001B[38;5;241m+\u001B[39m missing_arg_names\n\u001B[0;32m   3391\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m ConcreteFunction(\n\u001B[1;32m-> 3392\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3393\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3394\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3395\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3397\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3400\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3401\u001B[0m \u001B[43m        \u001B[49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   3403\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[0;32m   3404\u001B[0m     function_spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[0;32m   3405\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[0;32m   3406\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[0;32m   3407\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[0;32m   3408\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[0;32m   3409\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   3410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1184\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Returning a closed-over tensor does not trigger convert_to_tensor.\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   func_graph\u001B[38;5;241m.\u001B[39moutputs\u001B[38;5;241m.\u001B[39mextend(\n\u001B[0;32m   1180\u001B[0m       func_graph\u001B[38;5;241m.\u001B[39mcapture(x)\n\u001B[0;32m   1181\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flatten(func_graph\u001B[38;5;241m.\u001B[39mstructured_outputs)\n\u001B[0;32m   1182\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m-> 1184\u001B[0m   func_graph\u001B[38;5;241m.\u001B[39mvariables \u001B[38;5;241m=\u001B[39m variables\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m add_control_dependencies:\n\u001B[0;32m   1187\u001B[0m   func_graph\u001B[38;5;241m.\u001B[39mcontrol_outputs\u001B[38;5;241m.\u001B[39mextend(deps_control_manager\u001B[38;5;241m.\u001B[39mops_which_must_run)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:539\u001B[0m, in \u001B[0;36mAutomaticControlDependencies.__exit__\u001B[1;34m(self, unused_type, unused_value, unused_traceback)\u001B[0m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m r\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mbuilding_function:\n\u001B[0;32m    533\u001B[0m   \u001B[38;5;66;03m# There may be many stateful ops in the graph. Adding them as\u001B[39;00m\n\u001B[0;32m    534\u001B[0m   \u001B[38;5;66;03m# control inputs to each function output could create excessive\u001B[39;00m\n\u001B[0;32m    535\u001B[0m   \u001B[38;5;66;03m# control edges in the graph. Thus we create an intermediate No-op\u001B[39;00m\n\u001B[0;32m    536\u001B[0m   \u001B[38;5;66;03m# to chain the control dependencies between stateful ops and\u001B[39;00m\n\u001B[0;32m    537\u001B[0m   \u001B[38;5;66;03m# function outputs.\u001B[39;00m\n\u001B[0;32m    538\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 539\u001B[0m     control_output_op \u001B[38;5;241m=\u001B[39m \u001B[43mcontrol_flow_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mno_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    540\u001B[0m     control_output_op\u001B[38;5;241m.\u001B[39m_set_attr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_acd_function_control_output\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    541\u001B[0m                                 attr_value_pb2\u001B[38;5;241m.\u001B[39mAttrValue(b\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m    542\u001B[0m     control_output_op\u001B[38;5;241m.\u001B[39m_add_control_inputs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mops_which_must_run)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\ops\\gen_control_flow_ops.py:509\u001B[0m, in \u001B[0;36mno_op\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;66;03m# Add nodes to the TensorFlow graph.\u001B[39;00m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 509\u001B[0m   _, _, _op, _outputs \u001B[38;5;241m=\u001B[39m \u001B[43m_op_def_library\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_op_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNoOp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m    512\u001B[0m   _result \u001B[38;5;241m=\u001B[39m _dispatch\u001B[38;5;241m.\u001B[39mdispatch(\n\u001B[0;32m    513\u001B[0m         no_op, (), \u001B[38;5;28mdict\u001B[39m(name\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m    514\u001B[0m       )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:744\u001B[0m, in \u001B[0;36m_apply_op_helper\u001B[1;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[0;32m    739\u001B[0m must_colocate_inputs \u001B[38;5;241m=\u001B[39m [val \u001B[38;5;28;01mfor\u001B[39;00m arg, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(op_def\u001B[38;5;241m.\u001B[39minput_arg, inputs)\n\u001B[0;32m    740\u001B[0m                         \u001B[38;5;28;01mif\u001B[39;00m arg\u001B[38;5;241m.\u001B[39mis_ref]\n\u001B[0;32m    741\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001B[0;32m    742\u001B[0m   \u001B[38;5;66;03m# Add Op to graph\u001B[39;00m\n\u001B[0;32m    743\u001B[0m   \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m--> 744\u001B[0m   op \u001B[38;5;241m=\u001B[39m \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_op_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_type_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    745\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscope\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattr_protos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop_def\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    748\u001B[0m \u001B[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001B[39;00m\n\u001B[0;32m    749\u001B[0m \u001B[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001B[39;00m\n\u001B[0;32m    750\u001B[0m \u001B[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001B[39;00m\n\u001B[0;32m    751\u001B[0m \u001B[38;5;66;03m# for more details.\u001B[39;00m\n\u001B[0;32m    752\u001B[0m outputs \u001B[38;5;241m=\u001B[39m op\u001B[38;5;241m.\u001B[39moutputs\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:689\u001B[0m, in \u001B[0;36mFuncGraph._create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m    687\u001B[0m   inp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcapture(inp)\n\u001B[0;32m    688\u001B[0m   captured_inputs\u001B[38;5;241m.\u001B[39mappend(inp)\n\u001B[1;32m--> 689\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mFuncGraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_op_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    690\u001B[0m \u001B[43m    \u001B[49m\u001B[43mop_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_device\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3697\u001B[0m, in \u001B[0;36mGraph._create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m   3694\u001B[0m \u001B[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001B[39;00m\n\u001B[0;32m   3695\u001B[0m \u001B[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001B[39;00m\n\u001B[0;32m   3696\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mutation_lock():\n\u001B[1;32m-> 3697\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mOperation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3698\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnode_def\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3699\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3700\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3701\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3702\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcontrol_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontrol_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3703\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3704\u001B[0m \u001B[43m      \u001B[49m\u001B[43moriginal_op\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_default_original_op\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3705\u001B[0m \u001B[43m      \u001B[49m\u001B[43mop_def\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop_def\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3706\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_op_helper(ret, compute_device\u001B[38;5;241m=\u001B[39mcompute_device)\n\u001B[0;32m   3707\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2097\u001B[0m, in \u001B[0;36mOperation.__init__\u001B[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001B[0m\n\u001B[0;32m   2095\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m op_def \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2096\u001B[0m     op_def \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graph\u001B[38;5;241m.\u001B[39m_get_op_def(node_def\u001B[38;5;241m.\u001B[39mop)\n\u001B[1;32m-> 2097\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_c_op \u001B[38;5;241m=\u001B[39m \u001B[43m_create_c_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode_def\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2098\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mcontrol_input_ops\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2099\u001B[0m   name \u001B[38;5;241m=\u001B[39m compat\u001B[38;5;241m.\u001B[39mas_str(node_def\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m   2101\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_traceback \u001B[38;5;241m=\u001B[39m tf_stack\u001B[38;5;241m.\u001B[39mextract_stack_for_node(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_c_op)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\OD-3.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1909\u001B[0m, in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001B[0m\n\u001B[0;32m   1907\u001B[0m inputs \u001B[38;5;241m=\u001B[39m _reconstruct_sequence_inputs(op_def, inputs, node_def\u001B[38;5;241m.\u001B[39mattr)\n\u001B[0;32m   1908\u001B[0m \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m-> 1909\u001B[0m op_desc \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_NewOperation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1910\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1911\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1912\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m node_def\u001B[38;5;241m.\u001B[39mdevice:\n\u001B[0;32m   1913\u001B[0m   pywrap_tf_session\u001B[38;5;241m.\u001B[39mTF_SetDevice(op_desc, compat\u001B[38;5;241m.\u001B[39mas_str(node_def\u001B[38;5;241m.\u001B[39mdevice))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "replay_buffer = ReplayBuffer(replay_buffer_size)\n",
    "model = create_model(learning_rate, regularization_factor)\n",
    "target_model = copy_model(model)\n",
    "epsilon = starting_epsilon\n",
    "step_count = 0\n",
    "average_reward_tracker = AverageRewardTracker(100)\n",
    "file_logger = FileLogger()\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "  print(f\"Starting episode {episode} with epsilon {epsilon}\")\n",
    "\n",
    "  episode_reward = 0\n",
    "  state = env.reset()\n",
    "  fraction_finished = 0.0\n",
    "  state = np.append(state, fraction_finished)\n",
    "\n",
    "  first_q_values = get_q_values(model, state)\n",
    "  print(f\"Q values: {first_q_values}\")\n",
    "  print(f\"Max Q: {max(first_q_values)}\")\n",
    "\n",
    "  for step in range(1, max_steps + 1):\n",
    "    step_count += 1\n",
    "    q_values = get_q_values(model, state)\n",
    "    action = select_action_epsilon_greedy(q_values, epsilon)\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "\n",
    "    fraction_finished = (step + 1) / max_steps\n",
    "    new_state = np.append(new_state, fraction_finished)\n",
    "\n",
    "    episode_reward += reward\n",
    "\n",
    "    if step == max_steps:\n",
    "      print(f\"Episode reached the maximum number of steps. {max_steps}\")\n",
    "      done = True\n",
    "\n",
    "    state_transition = StateTransition(state, action, reward, new_state, done)\n",
    "    replay_buffer.add(state_transition)\n",
    "\n",
    "    state = new_state\n",
    "\n",
    "    if step_count % target_network_replace_frequency_steps == 0:\n",
    "      print(\"Updating target model\")\n",
    "      target_model = copy_model(model)\n",
    "\n",
    "    if replay_buffer.length() >= training_start and step_count % train_every_x_steps == 0:\n",
    "      batch = replay_buffer.get_batch(batch_size=training_batch_size)\n",
    "      targets = calculate_target_values(model, target_model, batch, discount_factor)\n",
    "      states = np.array([state_transition.old_state for state_transition in batch])\n",
    "      train_model(model, states, targets)\n",
    "\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "  average_reward_tracker.add(episode_reward)\n",
    "  average = average_reward_tracker.get_average()\n",
    "\n",
    "  print(\n",
    "    f\"episode {episode} finished in {step} steps with reward {episode_reward}. \"\n",
    "    f\"Average reward over last 100: {average}\")\n",
    "\n",
    "  if episode != 0 and episode % model_backup_frequency_episodes == 0:\n",
    "    backup_file = f\"model_{episode}.h5\"\n",
    "    print(f\"Backing up model to {backup_file}\")\n",
    "    model.save(backup_file)\n",
    "\n",
    "  epsilon *= epsilon_decay_factor_per_episode\n",
    "  epsilon = max(minimum_epsilon, epsilon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}